# 인공지능 FAQ

## 1. 인공지능에서 지능에 해당하는 기능은 무엇인가?
- 인공지능은 인간의 지능을 컴퓨터 시스템으로 구현하는 기술이다.
- 인공지능에서 지능은 인간이 가진 6가지 능력을 모방하거나 대체하는 역할을 한다.

### 1. 문제 해결 능력
- 주어진 문제를 분석하고 해결 방법을 찾는 능력이다.
- 예: 체스 AI는 가능한 모든 수를 계산하여 최적의 한 수를 선택한다.

### 2. 학습 능력
- 데이터를 기반으로 패턴을 학습하고, 새로운 데이터를 예측하거나 분류하는 능력이다.
- 예: 유튜브 추천 알고리즘은 사용자의 시청 기록을 분석하여 맞춤형 영상을 추천한다. AI는 지속적으로 데이터를 분석하며 사용자에게 잘 맞는 영상을 추천할 수 있다.

### 3. 추론 능력
- 기존 정보을 바탕으로 논리적으로 결론을 도출하는 능력이다.
- 예: 의료 AI는 환자의 증상과 기존 의료 데이터를 분석하여 질병을 진단할 수 있다.

### 4. 계획 수립 능력
- 목표를 달성하기 위해 최적의 행동 순서를 결정하는 능력이다.
- 예: 자율주행차는 교통 상황을 분석하여 가장 빠른 경로를 결정한다. 실시간 교통 정보를 사용하여 최적의 경로를 수정할 수 있다.

### 5. 인식 능력
- 이미지, 소리, 텍스트 등의 데이터를 감지하고 이해하는 능력이다.
- 예: 얼굴 인식 시스템이 사진 데이터를 분석하여 누구인지 알아낼 수 있다.

### 6. 언어 이해 및 생성 능력
- 텍스트나 음성을 이해하고, 적절한 대답을 생성하는 능력이다.
- 예: 챗봇은 사용자의 질문을 이해하고, 적절한 답변을 제공한다.

---

## 2. 인공지능의 종류 3가지 (지도학습, 반지도학습, 강화학습)
- 라벨링 : 데이터에 정답을 붙여주는 작업

### (1) 지도 학습
- 입력 데이터(x)와 정답 데이터(y)를 함께 제공하는 학습 방식이다.  
- AI 모델이 입력과 정답 간의 관계를 학습하여 패턴을 찾고, 새로운 입력에 대한 정답을 예측한다.  
#### 장단점
- **장점** : 데이터가 많을수록 정확도가 상승한다.  
- **단점** : 데이터 라벨링이 필요하여 시간과 비용이 많이 소요된다.  
#### 대표 응용 분야
1. **스팸 메일 필터링** : 메일이 스팸인지 정상인지 미리 학습한다.  
2. **이미지 분류** : 이미지와 정답을 함께 학습시켜 개, 고양이 등을 분류한다.
3. **손글씨 숫자 인식** : 손글씨로 작성한 숫자와 정답을 함께 학습시킨다.

### (2) 반지도 학습
- 일부 데이터는 정답이 있고 일부 데이터는 정답이 없는 상태에서 학습하는 방식이다.  
- 적은 양의 정답 데이터를 활용하여 성능을 개선한다.  
#### 장단점
- **장점** : 적은 정답 데이터를 사용하여 지도학습보다 비용이 적고, 일반화 성능이 좋다.  
- **단점** : 지도 학습에 비해 정확도가 떨어진다.  
#### 대표 응용 분야
1. **의료 영상 분석** : 일부 데이터는 전문가가 질병 여부를 라벨링했지만, 대부분은 라벨링되지 않은 데이터를 사용한다.  
2. **문서 분류** : 일부 문서만 사람이 직접 태그를 달고, 나머지는 AI가 추론하여 분류한다.  
3. **음성 인식** : 일부 녹음 파일에만 정확한 텍스트 변환이 포함된 경우에 활용된다.  

### (3) 강화 학습
- AI가 주어진 환경에서 직접 경험하며, 가장 좋은 결과를 얻을 수 있도록 스스로 학습하는 방법이다. 
- 특정한 행동을 했을 때 **보상**을 받거나 **벌점**을 받으며 최적의 행동을 찾아가는 과정이다.  
#### 장단점
- **장점** : 명확한 보상 시스템이 있을 때 스스로 최적의 행동 방법을 찾아 학습할 수 있다.  
- **단점** : 데이터 수집이 어렵고, 시간과 비용이 많이 소요된다.  
#### 대표 응용 분야
1. **알파고** : AI가 대국을 반복하며 스스로 학습하여 전략을 최적화한다.
2. **자율주행차** : 도로에서 안전한 주행을 하도록 반복 학습한다.  
3. **로봇 제어** : 로봇이 최적의 움직임을 찾도록 반복하여 스스로 학습한다.  

---

## 3. 전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점

### (1) 전통적인 프로그래밍 방법
- **사람이 직접** 명확한 규칙을 정의하여 프로그램을 작성하는 방식이다.
- 새로운 입력 데이터가 주어지면 정의된 규칙에 따라 결과가 도출된다.
#### 장단점
- **장점** : 오류 발생 가능성이 낮다.
- **단점** : 복잡한 문제에 적용하기 어렵다.

### (2) 인공지능 프로그램
- 사람이 직접 규칙을 정의하는 것이 아니라, **데이터에서 스스로 패턴을 학습**하여 문제를 해결하는 방식이다.
- 새로운 데이터가 들어왔을 때 학습한 패턴을 바탕으로 결과를 예측한다.
#### 장단점
- **장점** : 복잡한 패턴을 자동으로 학습할 수 있다. 사람이 직접 규칙을 정의하지 않아도 된다.
- **단점** : 학습을 위해 많은 데이터가 필요하고 훈련 과정이 오래 걸릴 수 있다.

---

## 4. 딥러닝과 머신러닝의 차이점

### (1) 머신러닝
- 데이터를 이용해 모델을 학습시키는 모든 기법을 포함하는 개념이다.
- **사람이 직접 특징을 추출**하여 모델을 학습시키고, 새로운 데이터가 들어왔을 때 결과를 예측하거나 분류한다.
- 적은 데이터로도 학습할 수 있고, 속도가 빠르다.
#### 대표 알고리즘
- SVM, KNN, 결정트리 등

### (2) 딥러닝
- 머신러닝에 속하는 하위 개념이다.
- 인공신경망을 여러 층 쌓은 구조를 사용해 **자동으로 특징을 추출**하여 학습한다.
- 이미지, 음성 등과 같이 데이터가 복잡할 때 효율적이다.
#### 대표 알고리즘
- CNN, RNN, Transformer 등

---

## 5. Classification과 Regression의 주된 차이점

### (1) Classification(분류)
- 주어진 데이터를 여러 개의 **이산적인** 범주 중 하나로 분류하는 방법이다.
#### 평가 지표
- Accuracy : 전체 예측 중에서 정답으로 맞춘 개수를 비율로 나타낸다.
 F1-Score : 클래스 간에 불균형이 있을 때 모델의 성능을 더 공정하게 평가할 수 있다
-  AUC : 이진 분류에서 모델이 정확하게 분류할 수 있게 해준다.
#### 대표적인 모델
- 로지스틱 회귀, SVM, 결정트리 등
#### 활용 분야
- 스팸 메일 필터링 : 메일을 **스팸 또는 정상**으로 분류한다.
- 의료 진단 : 질병 유무를 판단하거나 특정 질병의 종류를 분류한다.

### (2) Regression(회귀)
- 주어진 데이터에서 연속적인 숫자 값을 예측하는 방법이다.
#### 평가 지표
- MSE : 예측값과 실제값의 차이를 제곱한 값의 평균이다.
- RMSE : MSE의 제곱근을 구한 것이다.
 - MRE : 실제값에 대한 상대적인 오차 비율의 평균값이다. 데이터의 크기가 다양할 때, 상대적 성능을 비교할 수 있다.
#### 대표 모델
- 선형 회귀, Laso, Ridge 회귀
#### 활용 분야
- 주식 가격 예측은 과거 주가 데이터를 바탕으로 미래의 주가를 수치로 예측한다.
- 온도 예측 : 기상 데이터나 시간, 계절, 기압 등의 변수를 바탕으로 온도를 예측한다.

---

## 6. 머신러닝에서 차원의 저주 (curse of dimensionality)
- 데이터의 특성 수가 많아질 때, 차원이 증가할수록 데이터가 흩어져서 분포하는 현상이다.
- 데이터 간의 거리가 멀어져 비슷한 데이터를 찾기 어렵고, 데이터 간의 관계를 파악하기 어려워진다.
#### 문제점
- AI 모델이 중요하지 않은 정보까지 학습하게 되어, 새로운 데이터가 들어왔을 때 정확하게 예측하지 못한다.
- 학습 시간이 길어지고, 메모리도 더 많이 사용하게 된다.
- 불필요하거나 비슷한 특성을 제거하고, 꼭 필요한 정보만 모델에 학습시켜 문제를 해결할 수 있다.

---

## 7. Dimensionality Reduction가 필요한 이유
- 차원 감소는 데이터에서 불필요한 특성을 줄이고 중요한 정보만 남겨주는 작업이다.
- 데이터의 핵심적인 구조를 그대로 유지하며 중복되거나 의미없는 특성을 제외하어 간단한 형태로 변환하는 역할을 한다.
#### 필요한 이유
- 차원이 많아지면 데이터 간의 거리가 멀어져서 학습이 어려워진다.
- 불필요한 정보를 제거하여 더 정확하게 결과를 예측할 수 있다.
- 특성이 적어질수록 계산량이 줄고, 학습과 예측 속도가 빨라진다.

---

## 8. Ridge와 Lasso의 공통점과 차이점

### (1) 공통점
- `y = wx + b`형태의 예측을 하는 선형 모델이다.
- 규제의 강도를 조절하기 위해 람다를 사용한다.
- 과적합을 막고 모델이 너무 복잡해지지 않도록 제어하는 역할을 한다.

### (2) 차이점
#### Ridge
- 덜 중요한 특성을 제거하지는 않고 계수를 작게 만들어 결과에 미치는 영향을 약하게 한다.
#### Lasso
- 덜 중요한 특성의 계수를 0으로 만들어서 없애고 중요한 특성만 남겨서 모델을 간단하게 만든다.

---

## 9. Overfitting vs. Underfitting

### (1) Overfitting
- AI가 훈련 데이터를 너무 자세히 외워버린 상태이다.
- 데이터에 있는 불필요한 정보나 특이한 패턴까지 학습해서 새로운 데이터에 대해 예측을 잘 못하게 된다.
- Ridge, Lasso 등 정규화 방법으로 복잡도를 줄이면 해결할 수 있다.

### (2) Underfitting
- 모델이 너무 단순해서 중요한 패턴까지도 제대로 학습하지 못한 상태이다.
- 학습 데이터에서도 잘 예측하지 못하고, 새로운 데이터도 잘 예측하지 못한다.
- 특성을 추가하거나 학습을 반복하여 문제를 해결할 수 있다.

---

## 10. Feature Engineering과 Feature Selection의 차이점

### (1) Feature Engineering
- 모델이 더 잘 학습할 수 있도록 원래 데이터에서 새로운 특성을 만들어내는 과정이다.
- 예: 날씨 정보에서 요일, 계절 등의 특성을 만든다.

### (2) Feature Selection
- 이미 있는 특성 중에서 중요한 특성만을 골라내는 과정이다.
- 불필요한 데이터를 제거하여 모델의 예측 정확도를 높일 수 있다.

---

## 11. 전처리(Preprocessing)의 목적과 방법 (노이즈, 이상치, 결측치)

### (1) 목적
- 데이터를 깔끔하게 정리하여 AI 모델이 정확하게 학습할수 있게 한다.

### (2) 방법
#### 노이즈 제거
- 데이터에 포함된 불필요한 정보를 없애는 작업이다.
- 이동 평균, 가우시안 필터 등의 기법을 사용한다.
#### 이상치 처리
- 데이터에서 너무 크거나 작은 예외적인 값을 찾아내는 작업이다.
- 사분위 범위, 표준 점수 등의 기법을 사용한다.
#### 결측치 처리
- 데이터에서 비어있는 값을 채워넣는 작업이다.

---

## 12. EDA (Exploratory Data Analysis)란? 데이터의 특성 파악(분포, 상관관계)
- 머신러닝이나 데이터 분석을 시작하기 전에 데이터가 어떻게 생겼는지 먼저 살펴보는 작업이다.
- 데이터 분포, 이상치, 특성 간의 관계 등을 그래프나 통계 수치로 나타내어 전체적인 구조를 파악하게 해준다.
- 히스토그램, 산정도, 평균값, 최댓값 등을 사용한다.

---

## 13. 회귀에서 절편과 기울기의 의미 및 딥러닝과의 연관성

### (1) 회귀에서 절편과 기울기의 의미
- 회귀는 데이터에서 `y = wx + b`와 같은 규칙을 찾아서 결과를 예측하는 것이다.
- 절편 : 규칙에서 입력 데이터 x가 0일 때 예측되는 결과값이다.
- 기울기 : 입력 데이터 x가 변화할 때 예측값 y가 얼마나 변하는지를 나타내는 값이다.

### (2) 딥러닝과의 연관성
- 딥러닝은 회귀식을 여러 개 반복해서 복잡한 문제까지 해결할 수 있다.
- 딥러닝에서는 `y = w1x1 + w2x2 + ... + b`와 같은 식을 사용하는데, 이 식에서 기울기는 가중치, 절편은 편향이다.
- 가중치는 입력 값 x들이 y에 얼마나 영향을 주는지를 나타내는 값이다.
- 편향은 모든 입력값 x들이 0이어도 결과가 0이 되지 않게 해주는 값이다.

---

## 14. 교차검증과 K-fold 교차검증의 의미와 차이

### (1) 교차 검증
- 모델이 새로운 데이터에서도 정확히 예측하는지를 확인하는 평가방법이다.

### (2) K-fold 교차검증
- 전체 데이터를 K개의 작은 크기로 나눈 후, 하나는 검증에 사용하고 나머지는 학습에 사용하는 과정을 K번 반복하여 모든 데이터가 한 번씩은 검증에 쓰이게 한다.
- K번의 평가 결과를 평균내어 성능을 판단한다.

---


## 15. 하이퍼파라미터 튜닝이란 무엇인가?

- 하이퍼파라미터는 머신러닝이나 딥러닝에서 모델을 학습시키기 전에 직접 설정해줘야 하는 값이다.
- 하이퍼파라미터를 어떻게 설정하느냐에 따라 모델이 단순해질 수도 있고 복잡해질 수도 있다.
- 하이퍼파라미터 튜닝은 하이퍼파라미터를 적절히 설정하여 성능을 최대화하는 과정이다.
#### 방법
1. **그리드 탐색** : 모든 하이퍼파라미터들의 조합을 전부 시도해보는 방식이다.
2. **랜덤 탐색** : 무작위로 하이퍼파라미터 조합을 선택해서 테스트하는 방법이다.
3. **베이지안 최적화** : 이전에 시도한 결과를 바탕으로 다음에 시도할 조합을 효율적으로 선택하는 방법이다.

---

## 16. 결정트리에서 불순도(Impurity) – 지니 계수(Gini Index)란 무엇인가?

### (1) 불순도
- 데이터를 분류하는 과정에서 한 그룹 내에 다른 클래스들이 얼마나 들어 있는지를 나타내는 값이다.

### (2) 지니 계수
- 불순도를 계산하는 방법 중 하나이다.
- 한 그룹 내에서 두 데이터를 무작위로 골랐을 때 서로 다른 클래스에 속할 확률을 나타낸다.
- 지니계수 = 1 - (각 클래스 비율 제곱의 합)
- 0에 가까울수록 불순도가 낮고, 1에 가까울수록 불순도가 높다.

---

## 17. 앙상블이란 무엇인가?
- 여러 개의 모델을 결합해서 더 정확한 결과를 만드는 기법이다.
#### 앙상블 기법
1. 배깅 : 데이터를 중복을 허용하면서 여러 번 무작위로 뽑아서 여러 모델을 학습시키고, 결과를 회귀나 분류를 통해 결정한다.
2. 부스팅 : 성능이 낮은 모델 순서로 학습시키고, 이전 모델에서 틀린 데이터에 더 집중하여 학습을 진행한다.

---

## 18. 부트 스트랩핑(bootstrapping)이란 무엇인가?
- 원본 데이터에서 중복을 허용하면서 샘플을 여러 번 만드는 방법이다.
- 일부 데이터만을 이용하여 통계 분석을 할 수 있다.
- 많은 샘플을 생성해야 정확도가 올라가기 때문에 많은 시간이 소요된다.

---

## 19. 배깅(Bagging)이란 무엇인가?
- 앙상블 기법 중 하나이다.
- 원본 데이터에서 중복을 허용하면서 데이터를 뽑아 여러 번 샘플을 만들고, 여러 개의 모델에 학습시켜 분류나 회귀 방법으로 결과를 예측한다.
- 새로운 데이터가 들어왔을 때 제대로 예측하지 못하는 문제를 해결할 수 있고, 정확도를 높일 수 있다.
- Random Forest에서 사용한다.

---

## 20. 주성분 분석(PCA)이란 무엇인가?
- 복잡한 데이터를 데이터를 최대한 유지하면서 단순한 형태로 바꾸는 것이다.
- 각 데이터 간의 상관관계를 파악하고, 데이터의 분산을 설명하는 방향을 찾은 후, 전체적인 분산을 잘 나타내는 몇 개만을 선택하여 단순화한다.
- 모델의 학습속도를 올려주지만, 복잡한 패턴을 제대로 학습하지 못할 수 있다.