# 9주차

## 중간고사 리뷰

### 1. 전통적인 프로그래밍 VS 인공지능 프로그램

- 전통적: 개발자가 직접 규칙 정의
- 인공지능: 입력과 정답이 주어지면 인공지능이 스스로 규칙을 찾아 학습

### 2. 차원의 저주는 무엇이고 해결방법은?

- 차원의 저주: 특성의 수가 증가함에 따라 계산이 복잡해짐
- 해결방법: 차원의 축소, 규제

### 3. 딥러닝과 머신러닝의 차이

- 데이터 수집 → 전처리 → 모델 학습 → 평가
- 머신러닝: 모델을 학습하기 전에 데이터에서 특성 추출 (전문가적 방법)
- 딥러닝: 모델 자체에서 특징을 추출

### 4. 언더피팅과 오버피팅이 언제 발생하고 해결방법은?

1. 언더피팅
    - 학습이 충분하지 않아서 성능이 낮음
    - 모델 측면: 모델을 더 복잡하게 만들기
    - 데이터 측면: 데이터의 수 증대 - 시계열, 이미지에서의 상하반전
2. 오버피팅
    - 학습이 너무 지나치게 일어나서 노이즈까지 학습하여 일반화 성능이 떨어짐
    - 데이터 측면: 데이터의 수 감소 - , feacture selection, 규제

### 4. 계단함수, relu, sigmoid 사용목적과 차이점

- 활성화함수: 선형함수를 사용하여 층을 쌓아도 의미 없음 ⇒ 데이터에 비선형성 추가하여 복잡한 특징 추출 가능
- relu: 0 전까지는 0, 넘으면 입력값 그대로(양의 무한대로 증가). 층이 많아지면 미분값이 사라지는 문제 해결하기 위해 사용
- sigmoid: 0과 1 사이의 값. 뉴런을 활성화시킬 것인지 결정

### 5. 교차검증과 K-fold 교차검증

- 교차검증: 모든 데이터에서 잘 예측할 수 있도록 (일반화 성능) 하기 위해서
- 데이터를 k개의 폴드로 나누고, 하나의 폴드를 검증, 나머지는 학습용으로 사용하는 과정 반복

### 6. 하이퍼파라미터튜닝

- 레이어 개수, 뉴런 크기와 수, 활성화함수 종류와 같은 **하이퍼파리머터**를 조합해보며 모델의 성능을 최적화하는 것

### 7. KNN의 동작원리 간략히 설명

- 주변의 k개 데이터의 레이블을 참조하여 자신의 레이블을 결정하는 방법

### 8. 레이블의 불균형이 미치는 영향

- 한 쪽 데이터가 많을 때 한쪽으로 결과가 치우치는 문제

### 9. MSE

- 정답과 예측값의 차이를 제곱하여 계산
- 다음 예측을 더 잘 하기 위해서 bias와 weight를 업데이트

### 10. 앙상블과 부트스트패링

1. 앙상블
    - 여러 개의 모델을 사용하는 것
2. 부트스트래핑
    - 동일한 샘플에서 중복을 허용하여 무작위로 데이터를 뽑아 새로운 데이터셋 생성

### 13. 손실함수

- 그레디언트: 손실함수의미분값
- 다음 가중치 = 현재 가중치 - 학습률*미분값

### 14. CSV 파일을 모델 학습 전까지 과정

1. 파일 불러오기
2. 컬럼명 확인
3. 결측치 확인 및 처리
4. 라벨 인코딩
5. 스케일링
6. x, y 나누기
7. train, test 나누
8. 원-핫 인코딩
9. 넘파이로 변환
10. 레이블 개수 확인 - value_count()
11. 아웃레이어 제거 (박스플롯)

### 딥러닝

- 백프로파게이션: 손실함수 계산하여 weight와 bias 조정
- 옵티마이저: 경사하강법을 구현하여 손실 최적화

### 경사하강법

- 손실함수를 계산하여 weight와 bias를 최적화
- 배치: 전체 데이터 사용
- 확률: 일부 데이터만 뽑아서 사용
- 미니 배치: 전체 데이터를 그룹으로 나누어

---

## 과제

- ~6/9까지 레포트